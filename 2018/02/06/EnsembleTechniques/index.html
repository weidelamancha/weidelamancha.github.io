<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="technique," />










<meta name="description" content="IntroductionThis post aims to elucidate ensemble (also called committee-based learning, or learning multiple classifier systems) techniques used in machine learning.">
<meta name="keywords" content="technique">
<meta property="og:type" content="article">
<meta property="og:title" content="Ensemble Techniques">
<meta property="og:url" content="http://yoursite.com/2018/02/06/EnsembleTechniques/index.html">
<meta property="og:site_name" content="Studies of Data (currently under construction)">
<meta property="og:description" content="IntroductionThis post aims to elucidate ensemble (also called committee-based learning, or learning multiple classifier systems) techniques used in machine learning.">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2018-02-07T13:35:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ensemble Techniques">
<meta name="twitter:description" content="IntroductionThis post aims to elucidate ensemble (also called committee-based learning, or learning multiple classifier systems) techniques used in machine learning.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/02/06/EnsembleTechniques/"/>





  <title>Ensemble Techniques | Studies of Data (currently under construction)</title>
  








  <!-- 我加的：
  <meta charset="utf-8">
  <link rel="stylesheet" href="mermaid.min.css"> -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Studies of Data (currently under construction)</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">A blog about data scicence techniques and applications in business and bio/medical research</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/06/EnsembleTechniques/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="weidelamancha">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Studies of Data (currently under construction)">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Ensemble Techniques</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-06T00:00:00+08:00">
                2018-02-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>This post aims to elucidate ensemble (also called committee-based learning, or learning multiple classifier systems) techniques used in machine learning. </p>
<a id="more"></a>
<ul>
<li><p>Homogeneous ensemble</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	A((x)) --&gt; |base learning algorithm 1|B[base learner 1]</span><br><span class="line">	A --&gt; |base learning algorithm 1|C[base learner 2]</span><br><span class="line">	A --&gt; |base learning algorithm 1|D[base learner 3]	</span><br><span class="line">	B --&gt; E((y))</span><br><span class="line">	C --&gt; E</span><br><span class="line">	D --&gt; E</span><br></pre></td></tr></table></figure>
</li>
<li><p>Heterogeneous ensemble</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	A((x)) --&gt; |base learning algorithm 1|B[base/individual/component learner 1]</span><br><span class="line">	A --&gt; |base learning algorithm 2|C[base/individual/component learner 2]</span><br><span class="line">	A --&gt; |base learning algorithm 3|D[base/individual/component learner 3]	</span><br><span class="line">	B --&gt; E((y))</span><br><span class="line">	C --&gt; E</span><br><span class="line">	D --&gt; E</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>To get a good ensemble, it is generally believed that the base learners should be as accurate as possible, and as diverse as possible. Ensemble learning can be used online by updating weak learners and has been applied to object tracking and intrusion detection etc.</p>
<p><br></p>
<hr>
<h1 id="Core-knowledge-of-ensemble-methods"><a href="#Core-knowledge-of-ensemble-methods" class="headerlink" title="Core knowledge of ensemble methods"></a>Core knowledge of ensemble methods</h1><h3 id="1-Boosting"><a href="#1-Boosting" class="headerlink" title="1. Boosting"></a>1. Boosting</h3><p>Boosting works by training a set of learners <strong>sequentially</strong> and combining them for prediction, where the later learners focus more on the mistakes of the earlier learners.</p>
<p>General boosting procedure:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	A((D1)) --&gt; B[h1] </span><br><span class="line">	B --&gt; C&#123;e1, a1&#125;</span><br><span class="line">	C --&gt; D((D2))</span><br><span class="line">	D --&gt; E[h2]</span><br><span class="line">	E --&gt; F&#123;e2, a2&#125;</span><br><span class="line">	F --&gt; G((D3))</span><br><span class="line">	G --&gt; H[h3]</span><br><span class="line">	H --&gt; I&#123;e3, a3&#125;</span><br><span class="line">	I --&gt; J((D4))</span><br><span class="line">	B --&gt; K[H]</span><br><span class="line">	E --&gt; K</span><br><span class="line">	H --&gt; K</span><br></pre></td></tr></table></figure>
<p><em>Figure legend:<br>D: sample distribution; h: classifier; e: classification error of h; a: weight of h; H: ensembled classifier</em></p>
<h4 id="Adaboost-algorithm-Freund-and-Schapire-1997"><a href="#Adaboost-algorithm-Freund-and-Schapire-1997" class="headerlink" title="Adaboost algorithm [Freund and Schapire, 1997]:"></a>Adaboost algorithm [Freund and Schapire, 1997]:</h4><p>AdaBoost algorithm was designed as a classification algorithm for minimizing the misclassification error. It can be interpreted as a stagewise estimation procedure for fitting an additive logistic regression model.</p>
<ul>
<li>If base learning algorithm can learn with specified distributions, it is often accomplished by <strong><em>re-weighting</em></strong>: weighting training examples in each round according to the sample distribution.<br><strong>Pro:</strong> provides an option for <em>Boosting with restart</em> as a sanity check to ensure that the current base learner is better than random guess.</li>
<li>If not, it can be accomplished by <strong><em>re-sampling</em></strong>: sampling training examples in each round according to the desired distribution.<br><strong>Pro:</strong> especially for multi-class tasks, the base learner that cannot pass the sanity check can be removed, and a new data sample can be generated on which a new base learner will be trained; in this way, the AdaBoost procedure can avoid the problem of early-termination far before the specified number of rounds.</li>
</ul>
<p>Theoretically, it is necessary to constrain the complexity of base learners as well as the number of learning rounds; otherwise AdaBoost will overfit. However, <strong>empirically it often doesn’t overfit</strong>, as test error often tends to decrease even after the training error reaches zero. </p>
<p>The bound of <strong><em>generalization error</em></strong> is relevant to the <strong><em>margin</em></strong> (the margin of the classifier h on the instance x, or in other words, the distance of x to the classification hyperplane of h) , the number of learning rounds and the complexity of base learners. Margin distribution is believed crucial to the generalization performance of AdaBoost. Average margin or median margin are suggested to be considered as measures to compare margin distributions.</p>
<p>Variants of AdaBoost developed by considering different <strong><em>surrogate loss functions</em></strong>:</p>
<ul>
<li><strong><em>LogitBoost</em></strong> [Friedman et al., 2000] considers the log loss</li>
<li><strong><em>L2Boost</em></strong> [Bu ̈hlmann and Yu, 2003] considers the l2 loss</li>
</ul>
<p>Variants of AdaBoost for multi-class classification:</p>
<ul>
<li><strong><em>AdaBoost.M1</em></strong> [Freund and Schapire, 1997] in which base learners are multi-class learners instead of binary classifiers. This algorithm could not use binary classifiers, and requires every base learner has less than 1/2 multi-class 0/1-loss</li>
<li><strong><em>SAMME</em></strong> [Zhu et al., 2006], an improvement over AdaBoost.M1 with modifications of weight calculation</li>
<li><strong><em>AdaBoost.MH</em></strong> [Schapire and Singer, 1999] follows the one-versus-rest strategy. The real-value output H(x) rather than the crisp classification of<br>each AdaBoost classifier is used to identify the most probable class</li>
<li><strong><em>AdaBoost.M2</em></strong> [Freund and Schapire, 1997] follows the one-versus-one strategy, which minimizes a pseudo-loss</li>
<li><strong><em>AdaBoost.MR</em></strong> [Schapire and Singer, 1999] generalizes AdaBoost.M2 and minimizes a ranking loss motivated by the fact that the highest ranked class is more likely to be the correct class<br><del>Binary classifiers obtained by one-versus-one decomposition can also be aggregated by voting, pairwise coupling, directed acyclic graph, etc.</del></li>
</ul>
<p>AdaBoost algorithm has been observed to be very sensitive to <strong>noise</strong>. Because of AdaBoost’s exponential loss function, if an instance were not classified as its given label, the weight of this instance will increase drastically so that the instance to be classified according to the given label in the next round. Variants of AdaBoost are developed to increase noise tolerance by modifying weight updating rule for D:</p>
<ul>
<li><strong><em>MadaBoost</em></strong> [Domingo and Watanabe, 2000] sets an upper limit on the weights</li>
<li><strong><em>FilterBoost</em></strong> [Bradley and Schapire, 2008] does not employ the exponential loss function used in AdaBoost, but adopts the log loss function. The increase of the instance weights is upper bounded by 1, similar to the weight depressing in MadaBoost, but smoother</li>
<li>(<strong><em>BBM</em></strong> (Boosting-By-Majority) [Freund, 1995] -&gt; <strong><em>BrownBoost</em></strong> [Freund, 2001] -&gt; ) <strong><em>RobustBoost</em></strong> [Freund, 2009] boosts the normalized classification margin</li>
</ul>
<h3 id="2-Bagging"><a href="#2-Bagging" class="headerlink" title="2. Bagging"></a>2. Bagging</h3><p>Random Forest and some other random tree ensembles</p>
<h3 id="3-Combination-methods"><a href="#3-Combination-methods" class="headerlink" title="3. Combination methods"></a>3. Combination methods</h3><p>Averaging and voting<br>Stacking method<br>Mixture of experts</p>
<h3 id="4-Ensemble-diversity"><a href="#4-Ensemble-diversity" class="headerlink" title="4. Ensemble diversity"></a>4. Ensemble diversity</h3><p>error-ambiguity and bias-variance decompositions</p>
<hr>
<h1 id="Advanced-knowledge-of-ensemble-methods"><a href="#Advanced-knowledge-of-ensemble-methods" class="headerlink" title="Advanced knowledge of ensemble methods"></a>Advanced knowledge of ensemble methods</h1><h3 id="1-Ensemble-pruning"><a href="#1-Ensemble-pruning" class="headerlink" title="1. Ensemble pruning"></a>1. Ensemble pruning</h3><h3 id="2-Clustering-ensembles"><a href="#2-Clustering-ensembles" class="headerlink" title="2. Clustering ensembles"></a>2. Clustering ensembles</h3><h3 id="3-Ensemble-methods-in-semi-supervised-learning-active-learning-cost-sensitive-learning-and-class-imbalance-learning-as-well-as-comprehensibility-enhancement"><a href="#3-Ensemble-methods-in-semi-supervised-learning-active-learning-cost-sensitive-learning-and-class-imbalance-learning-as-well-as-comprehensibility-enhancement" class="headerlink" title="3. Ensemble methods in semi-supervised learning, active learning, cost-sensitive learning and class-imbalance learning, as well as comprehensibility enhancement"></a>3. Ensemble methods in semi-supervised learning, active learning, cost-sensitive learning and class-imbalance learning, as well as comprehensibility enhancement</h3><hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/technique/" rel="tag"># technique</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/02/05/HelloWorld/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">weidelamancha</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Core-knowledge-of-ensemble-methods"><span class="nav-number">2.</span> <span class="nav-text">Core knowledge of ensemble methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Boosting"><span class="nav-number">2.0.1.</span> <span class="nav-text">1. Boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Adaboost-algorithm-Freund-and-Schapire-1997"><span class="nav-number">2.0.1.1.</span> <span class="nav-text">Adaboost algorithm [Freund and Schapire, 1997]:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Bagging"><span class="nav-number">2.0.2.</span> <span class="nav-text">2. Bagging</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Combination-methods"><span class="nav-number">2.0.3.</span> <span class="nav-text">3. Combination methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Ensemble-diversity"><span class="nav-number">2.0.4.</span> <span class="nav-text">4. Ensemble diversity</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Advanced-knowledge-of-ensemble-methods"><span class="nav-number">3.</span> <span class="nav-text">Advanced knowledge of ensemble methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Ensemble-pruning"><span class="nav-number">3.0.1.</span> <span class="nav-text">1. Ensemble pruning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Clustering-ensembles"><span class="nav-number">3.0.2.</span> <span class="nav-text">2. Clustering ensembles</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Ensemble-methods-in-semi-supervised-learning-active-learning-cost-sensitive-learning-and-class-imbalance-learning-as-well-as-comprehensibility-enhancement"><span class="nav-number">3.0.3.</span> <span class="nav-text">3. Ensemble methods in semi-supervised learning, active learning, cost-sensitive learning and class-imbalance learning, as well as comprehensibility enhancement</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">weidelamancha</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
